{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "healthy-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428932, 3) 126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id    target\n",
       "0         0        5  0.004136\n",
       "1         0       11  0.001445\n",
       "2         0       16  0.002168\n",
       "3         0       31  0.002195\n",
       "4         0       62  0.001747"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PATH = \"../../input/optiver-realized-volatility-prediction\"\n",
    "\n",
    "def load_data(mode, path=PATH):\n",
    "    # mode = \"train\"/\"test\"\n",
    "    file_name = f'{path}/{mode}.csv'\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "df = load_data(\"train\")\n",
    "print(df.shape, df[\"stock_id\"].max())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "streaming-atlantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALE = 100\n",
    "PATH = \"../../input/optiver-realized-volatility-prediction\"\n",
    "\n",
    "order_book_paths = glob.glob(f'{PATH}/book_train.parquet/*/*')\n",
    "len(order_book_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "genuine-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_paths = glob.glob(f'{PATH}/trade_train.parquet/*/*')\n",
    "len(trade_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                                | 2/112 [00:14<12:56,  7.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4c7e141d9838>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtime_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbook_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mbooks_by_time\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbook_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbook_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"time_id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtime_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0morder_books\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstock_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooks_by_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3013\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3015\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3017\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3069\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3070\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "order_books = dict()\n",
    "\n",
    "\n",
    "for path in tqdm(order_book_paths):\n",
    "    stock_id = int(path.replace(\"\\\\\", \"/\").split(\"=\")[1].split(\"/\")[0])\n",
    "    book_df = pd.read_parquet(path)\n",
    "    books_by_time = dict()\n",
    "    \n",
    "    for time_id in book_df.time_id.unique():\n",
    "        books_by_time[time_id] = book_df[book_df[\"time_id\"] == time_id].reset_index(drop=True)\n",
    "    \n",
    "    order_books[stock_id] = books_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-equation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stunning-cover",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [04:47<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "trades = dict()\n",
    "\n",
    "\n",
    "for path in tqdm(trade_paths):\n",
    "    stock_id = int(path.replace(\"\\\\\", \"/\").split(\"=\")[1].split(\"/\")[0])\n",
    "    trade_df = pd.read_parquet(path)\n",
    "    trade_by_time = dict()\n",
    "    \n",
    "    for time_id in trade_df.time_id.unique():\n",
    "        trade_by_time[time_id] = trade_df[trade_df[\"time_id\"] == time_id].reset_index(drop=True)\n",
    "    \n",
    "    trades[stock_id] = trade_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "monetary-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for st_id in trades.keys():\n",
    "#     for t_id in tqdm(trades[st_id].keys()):\n",
    "#         filldf = pd.DataFrame({\"seconds_in_bucket\": range(600)})\n",
    "#         filldf = pd.merge(filldf, trades[st_id][t_id], on=[\"seconds_in_bucket\"], how=\"left\", suffixes=(\"_to_move\", \"\"))\n",
    "#         filldf.fillna(-1)\n",
    "#         trades[st_id][t_id] = filldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-pledge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-peninsula",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-proposal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "completed-amino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0615, -0.0337, -0.1055,  ..., -0.0334, -0.1405, -0.1566],\n",
       "         [-0.0615, -0.0337, -0.1055,  ..., -0.0334, -0.1405, -0.1566],\n",
       "         [-0.0615, -0.0337, -0.1055,  ..., -0.0334, -0.1405, -0.1566],\n",
       "         ...,\n",
       "         [ 0.1562,  0.1296, -0.1434,  ...,  0.1023, -0.1256, -0.1528],\n",
       "         [ 0.1562,  0.1296, -0.1434,  ...,  0.1023, -0.1256, -0.1528],\n",
       "         [ 0.1562,  0.1296, -0.1434,  ...,  0.1023, -0.1256, -0.1528]]),\n",
       " tensor([[-0.0439, -0.6405, -0.2857],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]]),\n",
       " tensor([0]),\n",
       " tensor([0.1445]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "# means_order = torch.FloatTensor([  0.9997,   1.0003, 769.9902, 766.7346,   0.9995,   1.0005, 959.3417,\n",
    "#         928.2203, 300])\n",
    "# stds_order = torch.FloatTensor([3.6881e-03, 3.6871e-03, 5.3541e+03, 4.9549e+03, 3.7009e-03, 3.6991e-03,\n",
    "#         6.6838e+03, 5.7353e+03, 300])\n",
    "\n",
    "means_order = torch.FloatTensor([  0.9997,   1.0003, 769.9902, 766.7346,   0.9995,   1.0005, 959.3417,\n",
    "        928.2203])\n",
    "stds_order = torch.FloatTensor([3.6881e-03, 3.6871e-03, 5.3541e+03, 4.9549e+03, 3.7009e-03, 3.6991e-03,\n",
    "        6.6838e+03, 5.7353e+03])\n",
    "\n",
    "# means_trade = torch.FloatTensor([300, 1.0, 100, 3.0])\n",
    "# stds_trade = torch.FloatTensor([300, 0.004, 153, 3.5])\n",
    "\n",
    "means_trade = torch.FloatTensor([1.0, 100, 3.0])\n",
    "stds_trade = torch.FloatTensor([0.004, 153, 3.5])\n",
    "\n",
    "\n",
    "\n",
    "class OptiverDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, aug=False):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.aug = aug\n",
    "        self.seq_len = 600\n",
    "        self.order_features = ['bid_price1', 'ask_price1', 'bid_size1', 'ask_size1','bid_price2', \n",
    "                         'ask_price2', 'bid_size2', 'ask_size2']#, \"seconds_in_bucket\"]\n",
    "        self.trade_features = [\"price\", \"size\", \"order_count\"]\n",
    "        \n",
    "    \n",
    "    def extract_features(self, data_dict, stock_id, time_id, features, means, stds):\n",
    "        X = -torch.ones((self.seq_len, len(features)))\n",
    "        try:\n",
    "            df = data_dict[stock_id][time_id]\n",
    "            feature_array = df[features].values\n",
    "            X[-feature_array.shape[0]:] = (torch.FloatTensor(feature_array) - means)/stds\n",
    "        except:\n",
    "            pass\n",
    "        return X\n",
    "    \n",
    "    def extract_book_features(self, data_dict, stock_id, time_id, features, means, stds):\n",
    "        X = torch.zeros((self.seq_len, len(features)))\n",
    "        df = data_dict[stock_id][time_id]\n",
    "\n",
    "        filldf = pd.DataFrame({\"seconds_in_bucket\": range(600)})\n",
    "        filldf = pd.merge(filldf, df, on=[\"seconds_in_bucket\"], how=\"left\")\n",
    "        filldf = filldf.fillna(method=\"ffill\")\n",
    "        X[:] = (torch.FloatTensor(filldf[features].values) - means)/stds\n",
    "#             second_in_bucket = df[\"seconds_in_bucket\"].values\n",
    "            \n",
    "#             for i in range(len(second_in_bucket)-1):\n",
    "#                 X[second_in_bucket[i]:second_in_bucket[i+1]] = (torch.FloatTensor(df[features].values[i]) - means)/stds\n",
    "                \n",
    "#             if second_in_bucket[-1] < 600:\n",
    "#                 X[second_in_bucket[-1]:] = (torch.FloatTensor(df[features].values[-1]) - means)/stds\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def extract_trade_features(self, data_dict, stock_id, time_id, features, means, stds):\n",
    "        X = -torch.ones((self.seq_len, len(features)))\n",
    "#         print(stock_id, time_id)\n",
    "#         try:\n",
    "        df = data_dict[stock_id][time_id]\n",
    "#         second_in_bucket = df[\"seconds_in_bucket\"].values\n",
    "\n",
    "        filldf = pd.DataFrame({\"seconds_in_bucket\": range(600)})\n",
    "        filldf = pd.merge(filldf, df, on=[\"seconds_in_bucket\"], how=\"left\")\n",
    "#         print(filldf)\n",
    "#         filldf = filldf.fillna(-1)\n",
    "#         print(filldf[features].values.shape)\n",
    "        X[:] = (torch.FloatTensor(filldf[features].values) - means)/stds\n",
    "        X[:] = torch.nan_to_num(X, nan=0)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        X1 = self.extract_book_features(order_books, row.stock_id, row.time_id, self.order_features,\n",
    "                                  means_order, stds_order)\n",
    "        try:\n",
    "            X2 = self.extract_trade_features(trades, row.stock_id, row.time_id, self.trade_features,\n",
    "                                      means_trade, stds_trade) \n",
    "        except:\n",
    "            X2 = -torch.ones((self.seq_len, len(self.trade_features)))\n",
    "\n",
    "        target = torch.FloatTensor([row.target*SCALE])\n",
    "        stock = torch.LongTensor([row.stock_id])\n",
    "        return X1, X2, stock, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "ds = OptiverDataset(df)\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "classified-cruise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stylish-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel_size, stride=1):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Conv1d(in_dim, out_dim, kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.bn(x)\n",
    "        return self.activation(x)\n",
    "        \n",
    "\n",
    "class SubModel(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.convs1 = nn.Sequential(ConvBlock(in_dim, 16, 3),\n",
    "                                   ConvBlock(16, 32, 3))\n",
    "        self.stock_conv = ConvBlock(36, 64, 4, stride=4)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(8)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(8)\n",
    "        self.convs2 = nn.Sequential(ConvBlock(128, 128, 2, stride=2),\n",
    "                                    ConvBlock(128, 32, 2, stride=2),\n",
    "                                    ConvBlock(32, 8, 2, stride=2))\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        x = self.convs1(x.transpose(2, 1))\n",
    "        x = self.stock_conv(torch.cat([x, s.repeat(1, 1, x.shape[2])], axis=1))\n",
    "        x = torch.cat([self.avg_pool(x), self.max_pool(x)], axis=1)\n",
    "        x = self.convs2(x).squeeze(-1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.order_model = SubModel(in_dim=8)\n",
    "        self.trade_model = SubModel(in_dim=3)\n",
    "        self.top = nn.Linear(16, 1)\n",
    "        self.stock_emb = nn.Embedding(127, 4)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x1, x2, s = inputs\n",
    "        s = self.stock_emb(s).transpose(2, 1)\n",
    "        \n",
    "        x1 = self.order_model(x1, s)\n",
    "        x2 = self.trade_model(x2, s)\n",
    "        x = self.top(torch.cat([x1, x2], axis=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funny-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "# def rmspe(y_true, y_pred):\n",
    "#     return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch < 1:\n",
    "        lr = 5e-5\n",
    "    elif epoch < 10:\n",
    "        lr = 1e-3\n",
    "    elif epoch < 27:\n",
    "        lr = 1e-4\n",
    "    else:\n",
    "        lr = 1e-5\n",
    "\n",
    "    for p in optimizer.param_groups:\n",
    "        p['lr'] = lr\n",
    "    return lr\n",
    "    \n",
    "def get_optimizer(net):\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n",
    "                                 eps=1e-08)\n",
    "    return optimizer\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    return (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "\n",
    "def loss_func(y_pred, y_true):\n",
    "    return torch.mean(torch.square((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs):\n",
    "    \n",
    "    optimizer = get_optimizer(model)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "        \n",
    "        lr = adjust_lr(optimizer, e)\n",
    "        \n",
    "        loss_list = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs)\n",
    "\n",
    "            loss = loss_func(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "            \n",
    "            avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n",
    "            \n",
    "        val_labels, val_preds = validate(model, val_loader)\n",
    "        val_metric = np.round(rmspe(val_labels, val_preds), 4)\n",
    "\n",
    "        train_metric = np.round(rmspe(np.concatenate(labels), np.concatenate(preds)), 4)\n",
    "        log_text = f\"Epoch {e+1}\\n Train metric: {train_metric}\\nValidation metric: {val_metric}\\n\"\n",
    "            \n",
    "        print(log_text)\n",
    "    return model, val_preds\n",
    "\n",
    "\n",
    "\n",
    "def kfold_train(BS=512, NW=7, NUM_FOLDS=5):\n",
    "    oof_preds = np.zeros(df.shape[0])\n",
    "\n",
    "    for fold in range(NUM_FOLDS):\n",
    "        print(f\"Fold {fold + 1}\")\n",
    "        train_ind = np.where(df[\"time_id\"].values % NUM_FOLDS != fold)[0]\n",
    "        val_ind = np.where(df[\"time_id\"].values % NUM_FOLDS == fold)[0]\n",
    "\n",
    "        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n",
    "\n",
    "\n",
    "        train_ds = OptiverDataset(train_df, aug=False)\n",
    "        val_ds = OptiverDataset(val_df, aug=False)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n",
    "                                  pin_memory=False, drop_last=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                                  pin_memory=False, drop_last=False)\n",
    "\n",
    "        model = Model()\n",
    "        model.cuda()\n",
    "        print(\"...... Start Training ......\")\n",
    "        model, val_preds = train(model, train_loader, val_loader, epochs=30)\n",
    "\n",
    "        oof_preds[val_ind] = val_preds\n",
    "\n",
    "        torch.save(model.state_dict(), f\"./NN/optiver_nn_v01_{fold}.pth\")\n",
    "        \n",
    "    df[\"nn_pred\"] = oof_preds/SCALE\n",
    "    df.to_csv(\"./NN/optiver_nn_v01_oof.csv\", index=False, columns=[\"stock_id\", \"time_id\", \"nn_pred\"])\n",
    "    \n",
    "    rmspe_score = rmspe(df[\"target\"], oof_preds/SCALE)\n",
    "    print(f\"Our out of folds RMSPE is {rmspe_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-exclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "...... Start Training ......\n",
      "  0%|                                                                                          | 0/676 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "kfold_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-vampire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-anchor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-oxygen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-injection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-samoa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = np.where(df[\"time_id\"].values % 5 != 1)[0]\n",
    "val_ind = np.where(df[\"time_id\"].values % 5 == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = OptiverDataset(train_df, aug=False)\n",
    "val_ds = OptiverDataset(val_df, aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, pin_memory=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for x in train_loader:\n",
    "    print(x[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-police",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-blake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-scout",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
